{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'contractions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ac9cb1e2352f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcontractions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCONTRACTION_MAP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0municodedata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mToktokTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'contractions'"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# Array\n",
    "import numpy as np\n",
    "\n",
    "# Decompress the file\n",
    "import gzip\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# text preprocessing\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from contractions import CONTRACTION_MAP\n",
    "import unicodedata\n",
    "tokenizer = ToktokTokenizer()\n",
    "nlp = spacy.load('en', parse=True, tag=True, entity=True)\n",
    "\n",
    "## Modeling\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "## Warnings\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "df2 = pd.read_csv('C:/users/eturk/Data_Science/Capstone_Project-Sentiment_Analysis/dataset/cleaned_review_beauty.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>product</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>pos_feedback</th>\n",
       "      <th>neg_feedback</th>\n",
       "      <th>rating_class</th>\n",
       "      <th>time</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15583</th>\n",
       "      <td>A7OCP4P0S4YO8</td>\n",
       "      <td>B00AE07BDU</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Axe is a favorite My son has used every produc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>axe favorite son use every product axe make lo...</td>\n",
       "      <td>['axe', 'favorite', 'son', 'use', 'every', 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14360</th>\n",
       "      <td>A1P2XYD265YE21</td>\n",
       "      <td>B00A0J084Y</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Axe Cooling Face Wash, Chilled Axe Cooling Fac...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>axe cool face wash chill axe cool face wash ch...</td>\n",
       "      <td>['axe', 'cool', 'face', 'wash', 'chill', 'axe'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8942</th>\n",
       "      <td>A1QBOC76MIOJYP</td>\n",
       "      <td>B006RFZ8C2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Biore Blemish Fighting Ice Cleanser This is a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>biore blemish fighting ice cleanser nice clean...</td>\n",
       "      <td>['biore', 'blemish', 'fighting', 'ice', 'clean...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             customer     product  rating  \\\n",
       "15583   A7OCP4P0S4YO8  B00AE07BDU     3.0   \n",
       "14360  A1P2XYD265YE21  B00A0J084Y     5.0   \n",
       "8942   A1QBOC76MIOJYP  B006RFZ8C2     5.0   \n",
       "\n",
       "                                             review_text  pos_feedback  \\\n",
       "15583  Axe is a favorite My son has used every produc...             0   \n",
       "14360  Axe Cooling Face Wash, Chilled Axe Cooling Fac...             1   \n",
       "8942   Biore Blemish Fighting Ice Cleanser This is a ...             0   \n",
       "\n",
       "       neg_feedback rating_class        time  \\\n",
       "15583             0      neutral  2013-02-26   \n",
       "14360             1         good  2013-04-14   \n",
       "8942              0         good  2013-05-15   \n",
       "\n",
       "                                              clean_text  \\\n",
       "15583  axe favorite son use every product axe make lo...   \n",
       "14360  axe cool face wash chill axe cool face wash ch...   \n",
       "8942   biore blemish fighting ice cleanser nice clean...   \n",
       "\n",
       "                                                  tokens  \n",
       "15583  ['axe', 'favorite', 'son', 'use', 'every', 'pr...  \n",
       "14360  ['axe', 'cool', 'face', 'wash', 'chill', 'axe'...  \n",
       "8942   ['biore', 'blemish', 'fighting', 'ice', 'clean...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample observations\n",
    "df2.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separating Response Variable and Feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate train set as X and test set as y\n",
    "X = df2['clean_text']\n",
    "y = df2['rating_class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting Dataset into Train and Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Dataset into train and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print train and test set shape\n",
    "print ('Train Set Shape\\t\\t:{}\\nTest Set Shape\\t\\t:{}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selecting the Right Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data imbalance is emphasized above, the evaluation of the classifier performance must be carried out using adequate metrics in order to take into account the class distribution and to pay more attention to the minority class. When the positive class is smaller and the ability to detect correctly positive samples is our main focus (correct detection of negatives examples is less important to the problem) we should use precision and recall. For our particular case, based on this thought I will use f1 score which is harmonic average of precision and recall as my evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix Plot Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title = 'Confusion matrix',\n",
    "                          cmap = plt.cm.summer):\n",
    "    \"\"\"\n",
    "    Create a confusion matrix plot for 'good','neutral', and 'bad' rating values \n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title, fontsize = 20)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, fontsize = 20)\n",
    "    plt.yticks(tick_marks, classes, fontsize = 20)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment = \"center\", \n",
    "                 color = \"white\" if cm[i, j] < thresh else \"black\", fontsize = 40)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label', fontsize = 30)\n",
    "    plt.xlabel('Predicted Label', fontsize = 30)\n",
    "\n",
    "    return plt\n",
    "\n",
    "def disp_confusion_matrix(y_pred, model_name):\n",
    "    \"\"\"\n",
    "    Display confusion matrix for selected model with countVectorizer\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plot = plot_confusion_matrix(cm, classes=['Bad','Good','Neutral'], normalize=False, \n",
    "                                 title = model_name + \" \" + 'with CV Confusion Matrix')\n",
    "    plt.show()\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a supervised multi-class classification problem. We are trying to predict the ratings based on the reviews left by females who bought beauty products in Amazon e-commerce system.  We used Python’s Scikit Learn libraries to solve our problem. In this context, we implemented Logistic Regression, Linear SVM and Random Forest, Gradient Boosting, XGBOOST, Naive Bayes, Catboost and TPOT algorithms. \n",
    "\n",
    "Since the ratings of the reviews was not distributed normally as seen below, we decided to decrease rating classes from 5 to 3 by merging Rating 1 and 2 as ‘Bad’, Rating 3 as Neutral and Rating 4 and 5 as Good and applied the algorithms. And finally we decreased the rating classes to 2 to check whether our algorithms will do better with binomial classification problem or not. To do so, we merged Rating 1 and 2 as ‘Bad’ as we did before, but this time Rating 3 joined to 4 and 5 as ‘Not Bad’ and applied the same models afterwards. We have already applied Count Vectorizing and TF-IDF separately to figure out which one has the better performance. Thus we managed to apply all possible combinations to get the best precision scores for the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Bag of Words (CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length.\n",
    "\n",
    "In order to address this, scikit-learn provides utilities for the most common ways to extract numerical features from text content, namely:\n",
    "\n",
    "- **tokenizing** strings and giving an integer id for each possible token, for instance by using white-spaces and punctuation as token separators.\n",
    "\n",
    "- **counting** the occurrences of tokens in each document.\n",
    "\n",
    "- **normalizing** and weighting with diminishing importance tokens that occur in the majority of samples / documents.\n",
    "\n",
    "In this scheme, features and samples are defined as follows:\n",
    "\n",
    "- each **individual token occurrence frequency** (normalized or not) is treated as a feature.\n",
    "\n",
    "- the vector of all the token frequencies for a given **document** is considered a multivariate sample.\n",
    "A corpus of documents can thus be represented by a matrix with one row per document and one column per token (e.g. word) occurring in the corpus.\n",
    "\n",
    "We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or “Bag of n-grams” representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.\n",
    "\n",
    "**\"CountVectorizer\"** implements both tokenization and occurrence counting in a single class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the word vector with CountVectorizer\n",
    "count_vect = CountVectorizer(ngram_range=(1,1), min_df = , max_df = )\n",
    "count_vect_train = count_vect.fit_transform(X_train)\n",
    "count_vect_train = count_vect_train.toarray()\n",
    "count_vect_test = count_vect.transform(X_test)\n",
    "count_vect_test = count_vect_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print vocabulary length\n",
    "print('Vocabulary length :', len(count_vect.get_feature_names()))\n",
    "print('Longest word   :', max(count_vect.vocabulary_, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature names of vector into a variable\n",
    "vocab = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for train countvectorizer dataset\n",
    "pd.DataFrame(count_vect_train, columns = vocab).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a function for models with CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling_countVec(Model):\n",
    "    \"\"\"\n",
    "    This function apply countVectorizer with machine learning algorithms. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Instantiate the classifier: model\n",
    "    model = Model\n",
    "    \n",
    "    # Fitting classifier to the Training set (all features)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    global y_pred\n",
    "    # Predicting the Test set results\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Assign f1 score to a variable\n",
    "    score = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    \n",
    "    # Printing evaluation metric (f1-score) \n",
    "    print(\"f1 score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Logistic Regression with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the modeling function for logistic regression with countvectorizer and print f1 score\n",
    "modeling_countVec(LogisticRegression(multi_class = 'multinomial', solver = 'newton-cg',\n",
    "                                     class_weight = 'balanced', C = 0.1, n_jobs = -1, random_state = 42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix for logistic regression with countvectorizer\n",
    "disp_confusion_matrix(y_pred, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Linear SVM with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the modeling function for linear support vector classification with countvectorizer and print f1 score\n",
    "modeling_countVec(LinearSVC(random_state = 42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix for linear SVM with countvectorizer\n",
    "disp_confusion_matrix(y_pred, \"Linear SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Random Forest with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the modeling function for random forest classifier with countvectorizer and print f1 score\n",
    "modeling_countVec(RandomForestClassifier(n_estimator = 200, random_state = 42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix for random forest classifier with countVectorizer\n",
    "disp_confusion_matrix(y_pred, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 Naive Bayes with CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the modeling function for naive bayes with countvectorizer and print f1 score\n",
    "modeling_countVec(MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix for naive bayes with countVectorizer\n",
    "disp_confusion_matrix(y_pred, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 Kernel SVM with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the modeling function for kernel SVM with countvectorizer and print f1 score\n",
    "modeling_countVec(SVC(kernel='rbf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix for kernel SVM with countVectorizer\n",
    "disp_confusion_matrix(y_pred, \"Kernel SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.6 Gradient Boosting with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the modeling function for gradient boosting with countvectorizer and print f1 score\n",
    "modeling_countVec(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix for gradient boosting with countVectorizer\n",
    "disp_confusion_matrix(y_pred, \"Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.7 XGBoost with CountVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the modeling function for XGBoost with countvectorizer and print f1 score\n",
    "modeling_countVec(XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix for gradient boosting with countVectorizer\n",
    "disp_confusion_matrix(y_pred, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.8 XGBoost with CountVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Bag of Words (CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
